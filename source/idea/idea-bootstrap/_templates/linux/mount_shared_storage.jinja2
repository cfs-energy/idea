# Begin: Mount Shared Storage
{% if context.base_os in ('amazonlinux2', 'amazonlinux2023', 'rhel8', 'rhel9', 'rocky8', 'rocky9', 'ubuntu2204', 'ubuntu2404') %}
  {% if context.has_storage_provider('fsx_lustre') or context.has_storage_provider('fsx_cache') %}
    {% include '_templates/linux/fsx_lustre_client.jinja2' %}
    REBOOT_REQUIRED=$(cat /root/bootstrap/reboot_required.txt)
    if [[ "${REBOOT_REQUIRED}" == "yes" ]]; then
      (crontab -l; echo "@reboot /bin/bash ${SCRIPT_DIR}/setup.sh crontab >> ${BOOTSTRAP_DIR}/logs/userdata_post_reboot.log 2>&1") | crontab -
      reboot
      exit 0
    fi
  {% endif %}
  function mount_shared_storage () {
    {% for name, storage in context.config.get_config('shared-storage').items() %}
      {% if context.eval_shared_storage_scope(shared_storage=storage) %}
        {% if storage['provider'] == 'efs' %}
        echo "# Using Provider {{ storage['provider'] }} for {{ storage['mount_dir'] }} using options {{ storage['mount_options'] }}"
        mkdir -p "{{ storage['mount_dir'] }}"
        add_efs_to_fstab "{{ storage['efs']['dns'] }}" \
                         "{{ storage['mount_dir'] }}" \
                         "{{ storage['mount_options'] }}"
        {% elif storage['provider'] in ('fsx_cache', 'fsx_lustre') %}
        # Check if lustre module is loaded
        if ! grep -q lustre /proc/filesystems; then
          echo "Lustre filesystem not detected in /proc/filesystems"

          # Check if lustre module is installed
          if modinfo lustre &>/dev/null; then
            echo "Lustre module is installed but not loaded, attempting to load..."
            modprobe lustre || echo "Failed to load lustre module"
          else
            echo "Lustre module is not installed. Please install lustre client package."
          fi
        fi

        # Check if lustre module is now loaded
        if grep -q lustre /proc/filesystems; then
          mkdir -p "{{ storage['mount_dir'] }}"
          add_fsx_lustre_to_fstab "{{ storage[storage['provider']]['dns'] }}" \
                                  "{{ storage['mount_dir'] }}" \
                                  "{{ storage['mount_options'] }}" \
                                  "{{ storage[storage['provider']]['mount_name'] }}"
        else
          echo "Lustre filesystem not available. Skipping mount for {{ storage['mount_dir'] }}"
        fi
        {% elif storage['provider'] == 'fsx_netapp_ontap' and storage['fsx_netapp_ontap']['volume']['security_style'] %}
        mkdir -p "{{ storage['mount_dir'] }}"
        add_fsx_netapp_ontap_to_fstab "{{ storage['fsx_netapp_ontap']['svm']['nfs_dns'] }}" \
                                      "{{ storage['mount_dir'] }}" \
                                      "{{ storage['mount_options'] }}" \
                                      "{{ storage['fsx_netapp_ontap']['volume']['volume_path'] }}"
        {% elif storage['provider'] == 'fsx_openzfs' %}
        mkdir -p "{{ storage['mount_dir'] }}"
        add_fsx_openzfs_to_fstab "{{ storage['fsx_openzfs']['dns'] }}" \
                                 "{{ storage['mount_dir'] }}" \
                                 "{{ storage['mount_options'] }}" \
                                 "{{ storage['fsx_openzfs']['volume_path'] }}"
        {% endif %}
      {% endif %}
    {% endfor %}

    local AWS=$(command -v aws)
    local FS_MOUNT_ATTEMPT=0
    local FS_MOUNT_MAX_ATTEMPTS=5
    mount -a
    local MOUNT_STATUS=$?
    # Error code 32 means filesystem is already mounted, which is not a failure
    while [[ ${MOUNT_STATUS} -ne 0 ]] && [[ ${MOUNT_STATUS} -ne 32 ]] && [[ ${FS_MOUNT_ATTEMPT} -le 5 ]]
    do
      local SLEEP_TIME=$(( RANDOM % 33 + 8 ))  # Minimum of 8 seconds sleep
      log_info "(${FS_MOUNT_ATTEMPT} of ${FS_MOUNT_MAX_ATTEMPTS}) Failed to mount FS (error ${MOUNT_STATUS}), retrying in ${SLEEP_TIME} seconds ..."
      sleep ${SLEEP_TIME}
      ((FS_MOUNT_ATTEMPT++))
      mount -a
      MOUNT_STATUS=$?
    done

    # Log success if we exited due to already mounted (code 32)
    if [[ ${MOUNT_STATUS} -eq 32 ]]; then
      log_info "Filesystems already mounted, continuing..."
    fi
  }
  mount_shared_storage
  {% if context.has_storage_provider('fsx_lustre') or context.has_storage_provider('fsx_cache') %}
    # Lustre client tuning for some adjustments takes place _after_ the client mounts have taken place
    {% include '_templates/linux/fsx_lustre_client_tuning_postmount.jinja2' %}
  {% endif %}
{% endif %}
# End: Mount Shared Storage
